----
#StatisticalMechanics 

The Principle of Maximum Entropy is the assertion that, among all possible distribution that satisfied the conditions to model the given data, the distribution with the maximum [[Gibbs Entropy]] is the optimal distribution.

For the distribution of any given discrete random variable $X$, the entropy of the distribution is defined as:
$$H(p(x)) = -\sum _x p(x) \log p(x)$$
And for continuous random variable $X$, it is given as:
$$H(p(x)) = - \int _D p(x) \log p(x) dx$$
- $D$ is the domain of the probabilistic distribution.
